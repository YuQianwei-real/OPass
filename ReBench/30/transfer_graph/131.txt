#[version = "0.0.5"]
def @main(%x0: Tensor[(1, 3, 224, 224), uint8] /* ty=Tensor[(1, 3, 224, 224), uint8] */, %x1: Tensor[(3, 224, 224), float32] /* ty=Tensor[(3, 224, 224), float32] */, %x2: Tensor[(224), float32] /* ty=Tensor[(224), float32] */) -> (Tensor[(1, 3, 224, 224), uint8], Tensor[(3, 224, 224), float32], (Tensor[(1, 3, 224, 224), float32], (Tensor[(1, 3, 224, 224), float32],)), Tensor[(1, 3, 224, 224), uint8], Tensor[(1, 3, 224, 224), float32], Tensor[(0, 5, 447, 224), float32], float32, Tensor[(1, 3, 224, 224), float32], Tensor[(224), float32], Tensor[(3, 224, 224), float32]) {
  let %x_0 = 2f /* ty=float32 span=from_string:3:16 */;
  let %x_1 = 114 /* ty=int32 span=from_string:4:17 */;
  let %x_2 = qnn.dequantize(%x0, %x_0, %x_1);
  let %x_3 = multiply(%x_2, %x_2);
  let %x_4 = ones_like(%x_3);
  let %x_5 = clip(%x0, a_min=114f, a_max=117f);
  let %x_6 = clip(%x_2, a_min=0f, a_max=6f);
  let %x_7 = reshape(%x_6, newshape=[3, 224, 224]);
  let %x_8 = zeros_like(%x_2);
  let %x_9 = multiply(%x_4, %x_2);
  let %x_10 = collapse_sum_like(%x_9, %x_2);
  let %x_11 = add(%x_8, %x_10);
  let %x_12 = multiply(%x_4, %x_2);
  let %x_13 = collapse_sum_like(%x_12, %x_2);
  let %x_14 = add(%x_11, %x_13);
  let %x_15 = (%x_14,);
  let %x_16 = (%x_3, %x_15);
  let %x_17 = clip(%x0, a_min=114f, a_max=117f);
  let %x_18 = ones_like(%x_8);
  let %x_19 = add(%x_8, %x_18);
  let %x_20 = nn.batch_to_space_nd(%x_11, block_shape=[2, 2], crops=[[0, 1], [0, 1]]);
  let %x_21 = 4f /* ty=float32 span=from_string:24:17 */;
  let %x_22 = nn.relu(%x_10);
  let %x_23 = transpose(%x_22, axes=[0, 2, 3, 1]);
  let %x_24 = transpose(%x_23, axes=[1, 2, 3, 0]);
  let %x_25 = transpose(%x_24, axes=[3, 2, 0, 1]);
  let %x_26 = collapse_sum_like(%x1, %x2);
  let %x_27 = 1f /* ty=float32 span=from_string:30:17 */;
  let %x_28 = add(%x_18, %x_27);
  let %x_29 = fast_exp(%x_28);
  let %x_30 = squeeze(%x_29);
  let %x_31 = (%x_5, %x_7, %x_16, %x_17, %x_19, %x_20, %x_21, %x_25, %x_26, %x_30);
  %x_31
}
