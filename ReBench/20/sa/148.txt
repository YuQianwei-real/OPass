#[version = "0.0.5"]
def @main(%x0: Tensor[(1, 4, 2), int8] /* ty=Tensor[(1, 4, 2), int8] span=from_string:6:23 */, %x1: Tensor[(1, 4, 2), int8] /* ty=Tensor[(1, 4, 2), int8] span=from_string:10:13 */, %x2: Tensor[(31, 65), int64] /* ty=Tensor[(31, 65), int64] span=from_string:14:13 */, %x3: Tensor[(58), float32] /* ty=Tensor[(58), float32] span=from_string:28:23 */, %x4: Tensor[(1, 100, 2), int8] /* ty=Tensor[(1, 100, 2), int8] span=from_string:24:24 */, %x5: Tensor[(1, 18, 2), int8] /* ty=Tensor[(1, 18, 2), int8] span=from_string:25:24 */, %x6: Tensor[(1, 46, 2), int8] /* ty=Tensor[(1, 46, 2), int8] span=from_string:23:24 */, %x7: Tensor[(49, 17, 31), int32] /* ty=Tensor[(49, 17, 31), int32] span=from_string:36:24 */) -> (Tensor[(1, 4, 4), float32], Tensor[(1, 4, 2), float32], Tensor[(1, 4, 100), float32], Tensor[(31, 65), int32], Tensor[(1, 100, 18), int8], Tensor[(1, 4, 2), float32], Tensor[(1, 18, 46), int8], (Tensor[(1), float32], (Tensor[(1), float32],)), Tensor[(1, 2), int32], Tensor[(1, 100, 18), int32]) {
  %0 = ones(shape=[1], dtype="float32");
  let %x8: Tensor[(1), float32] /* ty=Tensor[(1), float32] span=from_string:34:10 */ = multiply(%0, %0);
  let %x9: Tensor[(1), float32] /* ty=Tensor[(1), float32] span=from_string:17:19 */ = ones_like(%x8);
  %1 = qnn.dequantize(%x0, 2f /* ty=float32 span=from_string:6:30 */, 0 /* ty=int32 span=from_string:6:72 */);
  %2 = qnn.dequantize(%x1, 6f /* ty=float32 span=from_string:7:30 */, 0 /* ty=int32 span=from_string:7:72 */);
  %3 = nn.batch_matmul(%1, %2, transpose_b=True);
  %4 = add(%3, 1f /* ty=float32 span=from_string:9:18 */);
  %5 = cast(%x1, dtype="int16");
  %6 = cast(%5, dtype="int32");
  %7 = cast_like(%6, %x2);
  %8 = qnn.dequantize(%x4, 6f /* ty=float32 span=from_string:13:30 */, 0 /* ty=int32 span=from_string:13:73 */);
  %9 = cast(%x2, dtype="bool");
  %10 = qnn.batch_matmul(%x4, %x5, 0 /* ty=int32 span=from_string:15:37 */, 0 /* ty=int32 span=from_string:15:78 */, 2f /* ty=float32 span=from_string:15:120 */, 0.5f /* ty=float32 span=from_string:15:167 */, out_dtype="int32", transpose_b=True);
  %11 = qnn.batch_matmul(%x5, %x6, 0 /* ty=int32 span=from_string:16:37 */, 0 /* ty=int32 span=from_string:16:78 */, 2f /* ty=float32 span=from_string:16:120 */, 0.5f /* ty=float32 span=from_string:16:167 */, out_dtype="int32", transpose_b=True);
  %12 = multiply(%x9, %0);
  %13 = zeros_like(%0);
  %14 = collapse_sum_like(%12, %0);
  %15 = add(%13, %14);
  %16 = add(%15, %14);
  %17 = (%16,) /* ty=(Tensor[(1), float32],) span=from_string:34:15 */;
  %18 = qnn.dequantize(%x6, 2f /* ty=float32 span=from_string:23:31 */, 0 /* ty=int32 span=from_string:23:74 */);
  %19 = qnn.dequantize(%x4, 2f /* ty=float32 span=from_string:24:31 */, 0 /* ty=int32 span=from_string:24:74 */);
  %20 = qnn.dequantize(%x5, 0.5f /* ty=float32 span=from_string:25:33 */, 0 /* ty=int32 span=from_string:25:76 */);
  %21 = nn.batch_matmul(%19, %20, transpose_b=True);
  %22 = erf(%4);
  %23 = cast_like(%7, %x3);
  %24 = nn.batch_matmul(%1, %8, transpose_b=True);
  %25 = cast(%9, dtype="int32");
  %26 = qnn.requantize(%10, 1f /* ty=float32 span=from_string:31:31 */, 0 /* ty=int32 span=from_string:31:74 */, 1f /* ty=float32 span=from_string:31:116 */, 0 /* ty=int32 span=from_string:31:160 */, out_dtype="int8");
  %27 = add(%2, %0);
  %28 = qnn.requantize(%11, 1f /* ty=float32 span=from_string:33:31 */, 0 /* ty=int32 span=from_string:33:74 */, 1f /* ty=float32 span=from_string:33:116 */, 0 /* ty=int32 span=from_string:33:160 */, out_dtype="int8");
  %29 = (%x8, %17) /* ty=(Tensor[(1), float32], (Tensor[(1), float32],)) span=from_string:37:39 */;
  %30 = argmax(%18, axis=[1]);
  %31 = cast_like(%21, %x7);
  (%22, %23, %24, %25, %26, %27, %28, %29, %30, %31) /* ty=(Tensor[(1, 4, 4), float32], Tensor[(1, 4, 2), float32], Tensor[(1, 4, 100), float32], Tensor[(31, 65), int32], Tensor[(1, 100, 18), int8], Tensor[(1, 4, 2), float32], Tensor[(1, 18, 46), int8], (Tensor[(1), float32], (Tensor[(1), float32],)), Tensor[(1, 2), int32], Tensor[(1, 100, 18), int32]) span=from_string:37:3 */
}
