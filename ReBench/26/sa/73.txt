#[version = "0.0.5"]
def @main(%x0: Tensor[(1, 128, 56, 56), float32] /* ty=Tensor[(1, 128, 56, 56), float32] span=from_string:3:25 */, %x1: Tensor[(1, 128, 56, 56), float32] /* ty=Tensor[(1, 128, 56, 56), float32] span=from_string:23:23 */, %x2: Tensor[(128, 128, 3, 3), float32] /* ty=Tensor[(128, 128, 3, 3), float32] span=from_string:8:22 */, %x3: Tensor[(128, 128, 1, 1), float32] /* ty=Tensor[(128, 128, 1, 1), float32] span=from_string:15:17 */, %x4: Tensor[(128, 128, 3, 3), float32] /* ty=Tensor[(128, 128, 3, 3), float32] span=from_string:11:22 */, %x5: Tensor[(128, 56, 56), float32] /* ty=Tensor[(128, 56, 56), float32] */, %x6: float32 /* ty=float32 span=from_string:27:14 */, %x7: Tensor[(80, 128, 56, 56), float32] /* ty=Tensor[(80, 128, 56, 56), float32] span=from_string:14:15 */) -> (Tensor[(1, 128, 56, 56), float32], Tensor[(1, 32, 56, 56, 4), float32], Tensor[(0, 255, 111, 56), float32], Tensor[(1, 128, 56, 56), float32], Tensor[(3), int32], Tensor[(4), int32], Tensor[(81, 128, 56, 56), float32], Tensor[(128, 384), float32]) {
  %0 = layout_transform(%x0, src_layout="NCHW", dst_layout="NCHW4c") /* ty=Tensor[(1, 32, 56, 56, 4), float32] span=from_string:24:17 */;
  %1 = layout_transform(%0, src_layout="NCHW4c", dst_layout="NCHW") /* ty=Tensor[(1, 128, 56, 56), float32] span=from_string:5:16 */;
  %2 = nn.relu(%1) /* ty=Tensor[(1, 128, 56, 56), float32] span=from_string:7:12 */;
  %3 = subtract(%2, %x1) /* ty=Tensor[(1, 128, 56, 56), float32] span=from_string:23:19 */;
  %4 = add(%2, 1f /* ty=float32 span=from_string:7:18 */) /* ty=Tensor[(1, 128, 56, 56), float32] span=from_string:26:17 */;
  %5 = nn.conv2d(%4, %x2, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 56, 56), float32] span=from_string:10:12 */;
  %6 = add(1f /* ty=float32 span=from_string:9:14 */, %5) /* ty=Tensor[(1, 128, 56, 56), float32] span=from_string:10:16 */;
  %7 = add(%5, %6) /* ty=Tensor[(1, 128, 56, 56), float32] span=from_string:12:18 */;
  %8 = nn.conv2d(%7, %x4, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 56, 56), float32] span=from_string:25:30 */;
  %9 = nn.conv2d(%7, %x3, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 56, 56), float32] span=from_string:13:13 */;
  %10 = add(%9, %8) /* ty=Tensor[(1, 128, 56, 56), float32] span=from_string:14:10 */;
  %11 = (%10, %x7) /* ty=(Tensor[(1, 128, 56, 56), float32], Tensor[(80, 128, 56, 56), float32]) span=from_string:28:21 */;
  %12 = squeeze(%x3) /* ty=Tensor[(128, 128), float32] span=from_string:19:13 */;
  %13 = squeeze(%12) /* ty=Tensor[(128, 128), float32] span=from_string:18:13 */;
  %14 = add(%12, 1f /* ty=float32 span=from_string:17:20 */) /* ty=Tensor[(128, 128), float32] span=from_string:20:10 */;
  %15 = add(%13, 2f /* ty=float32 span=from_string:18:20 */) /* ty=Tensor[(128, 128), float32] span=from_string:20:15 */;
  %16 = add(%12, 1f /* ty=float32 span=from_string:19:20 */) /* ty=Tensor[(128, 128), float32] span=from_string:20:20 */;
  %17 = (%14, %15, %16) /* ty=(Tensor[(128, 128), float32], Tensor[(128, 128), float32], Tensor[(128, 128), float32]) span=from_string:21:21 */;
  %18 = concatenate(%17, axis=1) /* ty=Tensor[(128, 384), float32] span=from_string:22:17 */;
  %19 = squeeze(%18) /* ty=Tensor[(128, 384), float32] span=from_string:29:13 */;
  %20 = multiply(%3, %x1) /* ty=Tensor[(1, 128, 56, 56), float32] span=from_string:30:4 */;
  %21 = nn.relu(%0) /* ty=Tensor[(1, 32, 56, 56, 4), float32] span=from_string:30:9 */;
  %22 = nn.batch_to_space_nd(%8, block_shape=[2, 2], crops=[[0, 1], [0, 1]]) /* ty=Tensor[(0, 255, 111, 56), float32] span=from_string:30:14 */;
  %23 = reshape(%4, newshape=[1, 128, 56, 56]) /* ty=Tensor[(1, 128, 56, 56), float32] span=from_string:30:19 */;
  %24 = full(%x6, shape=[3], dtype="int32") /* ty=Tensor[(3), int32] span=from_string:30:24 */;
  %25 = concatenate(%11) /* ty=Tensor[(81, 128, 56, 56), float32] span=from_string:30:105 */;
  %26 = add(%19, 1f /* ty=float32 span=from_string:29:20 */) /* ty=Tensor[(128, 384), float32] span=from_string:30:110 */;
  (%20, %21, %22, %23, %24, meta[relay.Constant][0] /* ty=Tensor[(4), int32] span=from_string:30:34 */, %25, %26) /* ty=(Tensor[(1, 128, 56, 56), float32], Tensor[(1, 32, 56, 56, 4), float32], Tensor[(0, 255, 111, 56), float32], Tensor[(1, 128, 56, 56), float32], Tensor[(3), int32], Tensor[(4), int32], Tensor[(81, 128, 56, 56), float32], Tensor[(128, 384), float32]) span=from_string:3:3 */
}

#[metadata]
{
  "root": 1, 
  "nodes": [
    {
      "type_key": ""
    }, 
    {
      "type_key": "Map", 
      "keys": [
        "relay.Constant"
      ], 
      "data": [2]
    }, 
    {
      "type_key": "Array", 
      "data": [3]
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "8", 
        "data": "0", 
        "span": "6", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "VirtualDevice", 
      "attrs": {
        "device_type_int": "-1", 
        "memory_scope": "5", 
        "target": "0", 
        "virtual_device_id": "-1"
      }
    }, 
    {
      "type_key": "runtime.String"
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "34", 
        "end_column": "52", 
        "end_line": "30", 
        "line": "30", 
        "source_name": "7"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "from_string"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "9", 
        "span": "11"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [10]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "4"
      }
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "949", 
        "end_column": "969", 
        "end_line": "2", 
        "line": "2", 
        "source_name": "7"
      }
    }
  ], 
  "b64ndarrays": [
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAAgAQAEAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=="
  ], 
  "attrs": {"tvm_version": "0.13.0"}
}