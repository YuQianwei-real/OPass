#[version = "0.0.5"]
def @main(%x0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] span=from_string:5:29 */, %x1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] span=from_string:11:22 */) -> ((Tensor[(1, 64, 1, 1), float32], Tensor[(1, 64, 1, 1), float32]), float32, Tensor[(0, 127, 111, 56), float32], Tensor[(1, 64, 1, 1), float32], Tensor[(0, 111, 1, 1), float32], Tensor[(111, 56, 127, 0), float32]) {
  %0 = nn.global_max_pool2d(%x0);
  %1 = multiply(%0, 2f /* ty=float32 span=from_string:4:24 */);
  %2 = nn.batch_to_space_nd(%x0, block_shape=[2, 2], crops=[[0, 1], [0, 1]]);
  %3 = nn.relu(%2);
  %4 = transpose(%3, axes=[0, 2, 3, 1]);
  %5 = transpose(%4, axes=[1, 2, 3, 0]);
  %6 = ones(shape=[1], dtype="float32");
  %7 = add(%1, %6);
  %8 = nn.conv2d(%7, %x1, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);
  %9 = nn.global_max_pool2d(%4);
  %10 = nn.relu(%9);
  %11 = transpose(%10, axes=[0, 2, 3, 1]);
  %12 = transpose(%11, axes=[1, 2, 3, 0]);
  %13 = layout_transform(%5, src_layout="NCHW", dst_layout="NCHW4c");
  %14 = layout_transform(%13, src_layout="NCHW4c", dst_layout="NCHW");
  %15 = (%0, %1) /* ty=(Tensor[(1, 64, 1, 1), float32], Tensor[(1, 64, 1, 1), float32]) span=from_string:23:4 */;
  %16 = transpose(%5, axes=[3, 2, 0, 1]);
  %17 = nn.relu(%8);
  %18 = transpose(%12, axes=[3, 2, 0, 1]);
  %19 = nn.relu(%14);
  (%15, 7.38906f /* ty=float32 span=from_string:23:17 */, %16, %17, %18, %19) /* ty=((Tensor[(1, 64, 1, 1), float32], Tensor[(1, 64, 1, 1), float32]), float32, Tensor[(0, 127, 111, 56), float32], Tensor[(1, 64, 1, 1), float32], Tensor[(0, 111, 1, 1), float32], Tensor[(111, 56, 127, 0), float32]) span=from_string:3:3 */
}
