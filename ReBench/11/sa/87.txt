#[version = "0.0.5"]
def @main(%x0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] span=from_string:5:13 */, %x1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] span=from_string:26:10 */, %x2: Tensor[(4096, 3, 3), float32] /* ty=Tensor[(4096, 3, 3), float32] */, %x3: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %x4: float32 /* ty=float32 span=from_string:25:14 */, %x5: Tensor[(4, 64, 3, 3), float32] /* ty=Tensor[(4, 64, 3, 3), float32] span=from_string:26:15 */) -> (Tensor[(1, 128, 56, 56), float16], float32, Tensor[(64, 64, 3, 3), float16], Tensor[(64, 64, 3, 3), float16], Tensor[(1, 64, 56, 56), float16], Tensor[(4), int32], Tensor[(68, 64, 3, 3), float32], bool) {
  %0 = cast(%x1, dtype="float16");
  %1 = cast(2f /* ty=float32 span=from_string:4:15 */, dtype="float16");
  %2 = cast(%x0, dtype="float16");
  %3 = multiply(%0, %1);
  %4 = cast(0f /* ty=float32 span=from_string:7:15 */, dtype="float16");
  %5 = nn.conv2d(%2, %3, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], out_dtype="float16");
  %6 = add(%4, %5);
  %7 = nn.relu(%6);
  %8 = nn.max_pool2d(%7, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]);
  %9 = nn.upsampling(%8, scale_h=2f, scale_w=2f);
  %10 = (%9, %7) /* ty=(Tensor[(1, 64, 56, 56), float16], Tensor[(1, 64, 56, 56), float16]) span=from_string:14:21 */;
  %11 = concatenate(%10, axis=1);
  %12 = cast(1f /* ty=float32 span=from_string:15:16 */, dtype="float16");
  %13 = nn.relu(%3);
  %14 = cast(1f /* ty=float32 span=from_string:17:16 */, dtype="float16");
  %15 = nn.relu(%3);
  %16 = cast(1f /* ty=float32 span=from_string:19:16 */, dtype="float16");
  %17 = add(%13, %14);
  %18 = add(%15, %16);
  %19 = reshape(%13, newshape=[4096, 3, 3]);
  %20 = layout_transform(%9, src_layout="NCHW", dst_layout="NHWC");
  %21 = layout_transform(%20, src_layout="NHWC", dst_layout="NCHW");
  %22 = cast(%x4, dtype="float16");
  %23 = (%x1, %x5) /* ty=(Tensor[(64, 64, 3, 3), float32], Tensor[(4, 64, 3, 3), float32]) span=from_string:32:21 */;
  %24 = add(%11, %12);
  %25 = add(%17, %18);
  %26 = reshape(%19, newshape=[64, 64, 3, 3]);
  %27 = nn.relu(%21);
  %28 = full_like(meta[relay.Constant][0] /* ty=Tensor[(4), int32] span=from_string:31:24 */, %22);
  %29 = concatenate(%23);
  (%24, 2f /* ty=float32 span=from_string:33:11 */, %25, %26, %27, %28, %29, False /* ty=bool span=from_string:33:78 */) /* ty=(Tensor[(1, 128, 56, 56), float16], float32, Tensor[(64, 64, 3, 3), float16], Tensor[(64, 64, 3, 3), float16], Tensor[(1, 64, 56, 56), float16], Tensor[(4), int32], Tensor[(68, 64, 3, 3), float32], bool) span=from_string:3:3 */
}

#[metadata]
{
  "root": 1, 
  "nodes": [
    {
      "type_key": ""
    }, 
    {
      "type_key": "Map", 
      "keys": [
        "relay.Constant"
      ], 
      "data": [2]
    }, 
    {
      "type_key": "Array", 
      "data": [3]
    }, 
    {
      "type_key": "relay.Constant", 
      "attrs": {
        "_checked_type_": "8", 
        "data": "0", 
        "span": "6", 
        "virtual_device_": "4"
      }
    }, 
    {
      "type_key": "VirtualDevice", 
      "attrs": {
        "device_type_int": "-1", 
        "memory_scope": "5", 
        "target": "0", 
        "virtual_device_id": "-1"
      }
    }, 
    {
      "type_key": "runtime.String"
    }, 
    {
      "type_key": "Span", 
      "attrs": {
        "column": "24", 
        "end_column": "42", 
        "end_line": "31", 
        "line": "31", 
        "source_name": "7"
      }
    }, 
    {
      "type_key": "SourceName", 
      "repr_str": "from_string"
    }, 
    {
      "type_key": "relay.TensorType", 
      "attrs": {
        "dtype": "int32", 
        "shape": "9", 
        "span": "0"
      }
    }, 
    {
      "type_key": "Array", 
      "data": [10]
    }, 
    {
      "type_key": "IntImm", 
      "attrs": {
        "dtype": "int32", 
        "span": "0", 
        "value": "4"
      }
    }
  ], 
  "b64ndarrays": [
    "P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAQAAAAAgAQAEAAAAAAAAABAAAAAAAAAAQAAAAEAAAAADAAAAAwAAAA=="
  ], 
  "attrs": {"tvm_version": "0.13.0"}
}