#[version = "0.0.5"]
def @main(%x0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] span=from_string:8:22 */, %x1: Tensor[(54, 64, 1, 1), float32] /* ty=Tensor[(54, 64, 1, 1), float32] span=from_string:7:16 */, %x2: Tensor[(28, 60, 95, 44), int32] /* ty=Tensor[(28, 60, 95, 44), int32] span=from_string:10:22 */, %x3: Tensor[(3456, 1, 1), float32] /* ty=Tensor[(3456, 1, 1), float32] */, %x4: Tensor[(55, 64, 1, 1), float32] /* ty=Tensor[(55, 64, 1, 1), float32] */) -> (Tensor[(1, 64, 56, 56), float32], Tensor[(1, 64, 1, 1), float32], Tensor[(55, 64, 1, 1), int32], Tensor[(54, 64, 1, 1), float32], Tensor[(1), float32], int32) {
  %0 = ones(shape=[1], dtype="float32");
  %1 = nn.global_max_pool2d(%x0);
  %2 = (%1, %x1) /* ty=(Tensor[(1, 64, 1, 1), float32], Tensor[(54, 64, 1, 1), float32]) span=from_string:6:20 */;
  %3 = concatenate(%2);
  %4 = reshape(%x1, newshape=[3456, 1, 1]);
  %5 = multiply(%0, %x0);
  %6 = multiply(%1, %1);
  %7 = cast_like(%3, %x2);
  %8 = reshape(%4, newshape=[54, 64, 1, 1]);
  %9 = nn.fast_softmax(%0);
  (%5, %6, %7, %8, %9, 3520 /* ty=int32 span=from_string:13:28 */) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(1, 64, 1, 1), float32], Tensor[(55, 64, 1, 1), int32], Tensor[(54, 64, 1, 1), float32], Tensor[(1), float32], int32) span=from_string:3:3 */
}
