#[version = "0.0.5"]
def @main(%x0: Tensor[(1, 3, 224, 224), int8] /* ty=Tensor[(1, 3, 224, 224), int8] span=from_string:3:23 */, %x1: Tensor[(1, 3, 224, 224), int8] /* ty=Tensor[(1, 3, 224, 224), int8] span=from_string:14:24 */, %x2: Tensor[(3, 3, 3, 3), float32] /* ty=Tensor[(3, 3, 3, 3), float32] span=from_string:9:22 */, %x3: Tensor[(3, 3, 1, 1), float32] /* ty=Tensor[(3, 3, 1, 1), float32] span=from_string:12:22 */, %x4: Tensor[(3, 3, 3, 3), float32] /* ty=Tensor[(3, 3, 3, 3), float32] span=from_string:31:57 */, %x5: Tensor[(1, 3, 224, 89), int8] /* ty=Tensor[(1, 3, 224, 89), int8] span=from_string:17:15 */, %x6: Tensor[(1, 3, 224, 32), int8] /* ty=Tensor[(1, 3, 224, 32), int8] span=from_string:17:20 */, %x7: Tensor[(1, 3, 224, 4), int8] /* ty=Tensor[(1, 3, 224, 4), int8] span=from_string:17:25 */, %x8: Tensor[(224), float32] /* ty=Tensor[(224), float32] span=from_string:24:45 */, %x9: Tensor[(224), float32] /* ty=Tensor[(224), float32] span=from_string:24:40 */, %x10: Tensor[(224), float32] /* ty=Tensor[(224), float32] span=from_string:24:34 */, %x11: Tensor[(224), float32] /* ty=Tensor[(224), float32] span=from_string:24:28 */) -> (Tensor[(1, 3, 224, 224), float16], Tensor[(1, 3, 224, 224), float32], Tensor[(1, 3, 224, 349), int8], Tensor[(1, 3, 224, 224), float32], Tensor[(3, 3, 3, 3), float32], Tensor[(1, 224, 3, 224), float32], Tensor[(1, 1, 3, 224, 224), int8]) {
  %0 = qnn.dequantize(%x0, 0.1f /* ty=float32 span=from_string:3:32 */, 0 /* ty=int32 span=from_string:3:74 */) /* ty=Tensor[(1, 3, 224, 224), float32] span=from_string:15:19 */;
  %1 = nn.softmax(%0) /* ty=Tensor[(1, 3, 224, 224), float32] span=from_string:27:14 */;
  let %x14: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] span=from_string:8:12 */ = add(2f /* ty=float32 span=from_string:7:121 */, %1) /* ty=Tensor[(1, 3, 224, 224), float32] span=from_string:7:115 */;
  %2 = add(%x14, 1f /* ty=float32 span=from_string:8:20 */) /* ty=Tensor[(1, 3, 224, 224), float32] span=from_string:9:18 */;
  %3 = nn.conv2d(%2, %x2, padding=[1, 1, 1, 1], channels=3, kernel_size=[3, 3]) /* ty=Tensor[(1, 3, 224, 224), float32] span=from_string:11:12 */;
  %4 = add(1f /* ty=float32 span=from_string:10:14 */, %3) /* ty=Tensor[(1, 3, 224, 224), float32] span=from_string:11:16 */;
  %5 = add(%3, %4) /* ty=Tensor[(1, 3, 224, 224), float32] span=from_string:13:18 */;
  %6 = nn.conv2d(%5, %x3, padding=[0, 0, 0, 0], channels=3, kernel_size=[1, 1]) /* ty=Tensor[(1, 3, 224, 224), float32] span=from_string:28:13 */;
  %7 = nn.conv2d(%5, %x4, padding=[1, 1, 1, 1], channels=3, kernel_size=[3, 3]) /* ty=Tensor[(1, 3, 224, 224), float32] span=from_string:28:17 */;
  %8 = qnn.dequantize(%x1, 0.2f /* ty=float32 span=from_string:14:33 */, 0 /* ty=int32 span=from_string:14:76 */) /* ty=Tensor[(1, 3, 224, 224), float32] span=from_string:15:23 */;
  %9 = multiply(%0, %8) /* ty=Tensor[(1, 3, 224, 224), float32] span=from_string:20:26 */;
  %10 = qnn.quantize(%9, 20f /* ty=float32 span=from_string:16:30 */, 0 /* ty=int32 span=from_string:16:73 */, out_dtype="int8") /* ty=Tensor[(1, 3, 224, 224), int8] span=from_string:33:21 */;
  %11 = (%10, %x5, %x6, %x7) /* ty=(Tensor[(1, 3, 224, 224), int8], Tensor[(1, 3, 224, 89), int8], Tensor[(1, 3, 224, 32), int8], Tensor[(1, 3, 224, 4), int8]) span=from_string:29:25 */;
  %12 = (0.5f /* ty=float32 span=from_string:18:14 */, 1.5f /* ty=float32 span=from_string:18:60 */, 2.5f /* ty=float32 span=from_string:18:106 */, 3.5f /* ty=float32 span=from_string:18:153 */) /* ty=(float32, float32, float32, float32) span=from_string:29:30 */;
  %13 = (0 /* ty=int32 span=from_string:19:11 */, 0 /* ty=int32 span=from_string:19:52 */, 0 /* ty=int32 span=from_string:19:93 */, 0 /* ty=int32 span=from_string:19:134 */) /* ty=(int32, int32, int32, int32) span=from_string:29:35 */;
  %14 = layout_transform(%9, src_layout="NHWC", dst_layout="NCHW4c") /* ty=Tensor[(1, 56, 3, 224, 4), float32] */;
  %15 = nn.relu(%14) /* ty=Tensor[(1, 56, 3, 224, 4), float32] span=from_string:23:26 */;
  %16 = layout_transform(%15, src_layout="NCHW4c", dst_layout="NCHW") /* ty=Tensor[(1, 224, 3, 224), float32] span=from_string:30:26 */;
  %17 = nn.batch_norm(%16, %x11, %x10, %x9, %x8) /* ty=(Tensor[(1, 224, 3, 224), float32], Tensor[(224), float32], Tensor[(224), float32]) span=from_string:26:9 */;
  %18 = %17.0 /* ty=Tensor[(1, 224, 3, 224), float32] span=from_string:32:13 */;
  %19 = %17.0 /* ty=Tensor[(1, 224, 3, 224), float32] span=from_string:32:18 */;
  %20 = cast(%1, dtype="float16") /* ty=Tensor[(1, 3, 224, 224), float16] span=from_string:34:4 */;
  %21 = add(%6, %7) /* ty=Tensor[(1, 3, 224, 224), float32] span=from_string:34:9 */;
  %22 = qnn.concatenate(%11, %12, %13, 3.5f /* ty=float32 span=from_string:29:44 */, 0 /* ty=int32 span=from_string:29:87 */, axis=-1) /* ty=Tensor[(1, 3, 224, 349), int8] span=from_string:34:14 */;
  %23 = layout_transform(%16, src_layout="NCHW", dst_layout="NHWC") /* ty=Tensor[(1, 3, 224, 224), float32] span=from_string:34:19 */;
  %24 = add(2f /* ty=float32 span=from_string:31:15 */, %x4) /* ty=Tensor[(3, 3, 3, 3), float32] span=from_string:34:24 */;
  %25 = add(%18, %19) /* ty=Tensor[(1, 224, 3, 224), float32] span=from_string:34:29 */;
  %26 = expand_dims(%10, axis=1) /* ty=Tensor[(1, 1, 3, 224, 224), int8] span=from_string:34:34 */;
  (%20, %21, %22, %23, %24, %25, %26) /* ty=(Tensor[(1, 3, 224, 224), float16], Tensor[(1, 3, 224, 224), float32], Tensor[(1, 3, 224, 349), int8], Tensor[(1, 3, 224, 224), float32], Tensor[(3, 3, 3, 3), float32], Tensor[(1, 224, 3, 224), float32], Tensor[(1, 1, 3, 224, 224), int8]) span=from_string:34:3 */
}
