#[version = "0.0.5"]
def @main(%x0: Tensor[(1, 3, 224, 224), int8] /* ty=Tensor[(1, 3, 224, 224), int8] span=from_string:3:23 */, %x1: Tensor[(1, 3, 224, 224), int8] /* ty=Tensor[(1, 3, 224, 224), int8] span=from_string:12:23 */, %x2: Tensor[(3, 3, 3, 3), float32] /* ty=Tensor[(3, 3, 3, 3), float32] span=from_string:7:22 */, %x3: Tensor[(3, 3, 1, 1), float32] /* ty=Tensor[(3, 3, 1, 1), float32] span=from_string:10:22 */, %x4: Tensor[(3, 3, 3, 3), float32] /* ty=Tensor[(3, 3, 3, 3), float32] span=from_string:39:57 */, %x5: Tensor[(1, 3, 224, 89), int8] /* ty=Tensor[(1, 3, 224, 89), int8] span=from_string:16:24 */, %x6: Tensor[(1, 3, 224, 32), int8] /* ty=Tensor[(1, 3, 224, 32), int8] span=from_string:19:24 */, %x7: Tensor[(1, 3, 224, 4), int8] /* ty=Tensor[(1, 3, 224, 4), int8] span=from_string:20:24 */, %x8: Tensor[(224), float32] /* ty=Tensor[(224), float32] span=from_string:30:45 */, %x9: Tensor[(224), float32] /* ty=Tensor[(224), float32] span=from_string:30:40 */, %x10: Tensor[(224), float32] /* ty=Tensor[(224), float32] span=from_string:30:34 */, %x11: Tensor[(224), float32] /* ty=Tensor[(224), float32] span=from_string:30:28 */) -> (Tensor[(1, 3, 224, 224), float16], Tensor[(1, 3, 224, 224), float32], Tensor[(1, 3, 224, 349), int8], Tensor[(1, 3, 224, 224), float32], Tensor[(3, 3, 3, 3), float32], Tensor[(1, 224, 3, 224), float32], Tensor[(1, 1, 3, 224, 224), int8]) {
  let %x_0 = 0.1f /* ty=float32 span=from_string:3:32 */;
  let %x_1 = 0 /* ty=int32 span=from_string:3:74 */;
  let %x_2 = qnn.dequantize(%x0, %x_0, %x_1);
  let %x_3 = nn.softmax(%x_2);
  let %x_4 = cast(%x_3, dtype="float16");
  let %x_5 = 2f /* ty=float32 span=from_string:5:14 */;
  let %x_6 = add(%x_5, %x_3);
  let %x_7 = 1f /* ty=float32 span=from_string:6:18 */;
  let %x_8 = add(%x_6, %x_7);
  let %x_9 = nn.conv2d(%x_8, %x2, padding=[1, 1, 1, 1], channels=3, kernel_size=[3, 3]);
  let %x_10 = 1f /* ty=float32 span=from_string:8:14 */;
  let %x_11 = add(%x_10, %x_9);
  let %x_12 = add(%x_9, %x_11);
  let %x_13 = nn.conv2d(%x_12, %x3, padding=[0, 0, 0, 0], channels=3, kernel_size=[1, 1]);
  let %x_14 = nn.conv2d(%x_12, %x4, padding=[1, 1, 1, 1], channels=3, kernel_size=[3, 3]);
  let %x_15 = add(%x_13, %x_14);
  let %x_16 = 0.2f /* ty=float32 span=from_string:12:32 */;
  let %x_17 = 0 /* ty=int32 span=from_string:12:75 */;
  let %x_18 = qnn.dequantize(%x1, %x_16, %x_17);
  let %x_19 = multiply(%x_2, %x_18);
  let %x_20 = 20f /* ty=float32 span=from_string:14:30 */;
  let %x_21 = 0 /* ty=int32 span=from_string:14:73 */;
  let %x_22 = qnn.quantize(%x_19, %x_20, %x_21, out_dtype="int8");
  let %x_23 = 0.5f /* ty=float32 span=from_string:15:33 */;
  let %x_24 = 0 /* ty=int32 span=from_string:15:76 */;
  let %x_25 = qnn.dequantize(%x_22, %x_23, %x_24);
  let %x_26 = 1.5f /* ty=float32 span=from_string:16:33 */;
  let %x_27 = 0 /* ty=int32 span=from_string:16:76 */;
  let %x_28 = qnn.dequantize(%x5, %x_26, %x_27);
  let %x_29 = (%x_25, %x_28) /* ty=(Tensor[(1, 3, 224, 224), float32], Tensor[(1, 3, 224, 89), float32]) span=from_string:18:21 */;
  let %x_30 = concatenate(%x_29, axis=-1);
  let %x_31 = annotation.stop_fusion(%x_30);
  let %x_32 = 2.5f /* ty=float32 span=from_string:19:33 */;
  let %x_33 = 0 /* ty=int32 span=from_string:19:76 */;
  let %x_34 = qnn.dequantize(%x6, %x_32, %x_33);
  let %x_35 = 3.5f /* ty=float32 span=from_string:20:33 */;
  let %x_36 = 0 /* ty=int32 span=from_string:20:76 */;
  let %x_37 = qnn.dequantize(%x7, %x_35, %x_36);
  let %x_38 = (%x_34, %x_37) /* ty=(Tensor[(1, 3, 224, 32), float32], Tensor[(1, 3, 224, 4), float32]) span=from_string:22:21 */;
  let %x_39 = concatenate(%x_38, axis=-1);
  let %x_40 = annotation.stop_fusion(%x_39);
  let %x_41 = (%x_31, %x_40) /* ty=(Tensor[(1, 3, 224, 313), float32], Tensor[(1, 3, 224, 36), float32]) span=from_string:26:21 */;
  let %x_42 = concatenate(%x_41, axis=-1);
  let %x_43 = 3.5f /* ty=float32 span=from_string:37:31 */;
  let %x_44 = 0 /* ty=int32 span=from_string:37:74 */;
  let %x_45 = qnn.quantize(%x_42, %x_43, %x_44, out_dtype="int8");
  let %x_46 = layout_transform(%x_19, src_layout="NHWC", dst_layout="NCHW4c");
  let %x_47 = nn.relu(%x_46);
  let %x_48 = layout_transform(%x_47, src_layout="NCHW4c", dst_layout="NCHW");
  let %x_49 = layout_transform(%x_48, src_layout="NCHW", dst_layout="NHWC");
  let %x_50 = 2f /* ty=float32 span=from_string:39:15 */;
  let %x_51 = add(%x_50, %x4);
  let %x_52 = nn.batch_norm(%x_48, %x11, %x10, %x9, %x8);
  let %x_53 = %x_52.0;
  let %x_54 = %x_52.0;
  let %x_55 = add(%x_53, %x_54);
  let %x_56 = 2f /* ty=float32 span=from_string:33:31 */;
  let %x_57 = 0 /* ty=int32 span=from_string:33:74 */;
  let %x_58 = qnn.dequantize(%x_22, %x_56, %x_57);
  let %x_59 = expand_dims(%x_58, axis=1);
  let %x_60 = 2f /* ty=float32 span=from_string:41:29 */;
  let %x_61 = 0 /* ty=int32 span=from_string:41:72 */;
  let %x_62 = qnn.quantize(%x_59, %x_60, %x_61, out_dtype="int8");
  let %x_63 = (%x_4, %x_15, %x_45, %x_49, %x_51, %x_55, %x_62) /* ty=(Tensor[(1, 3, 224, 224), float16], Tensor[(1, 3, 224, 224), float32], Tensor[(1, 3, 224, 349), int8], Tensor[(1, 3, 224, 224), float32], Tensor[(3, 3, 3, 3), float32], Tensor[(1, 224, 3, 224), float32], Tensor[(1, 1, 3, 224, 224), int8]) span=from_string:3:3 */;
  %x_63
}
