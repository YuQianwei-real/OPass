#[version = "0.0.5"]
def @main(%x0: Tensor[(1, 3, 224, 224), int8] /* ty=Tensor[(1, 3, 224, 224), int8] span=from_string:3:23 */, %x1: Tensor[(1, 3, 224, 224), int8] /* ty=Tensor[(1, 3, 224, 224), int8] span=from_string:12:23 */, %x2: Tensor[(3, 3, 3, 3), float32] /* ty=Tensor[(3, 3, 3, 3), float32] span=from_string:7:22 */, %x3: Tensor[(3, 3, 1, 1), float32] /* ty=Tensor[(3, 3, 1, 1), float32] span=from_string:10:22 */, %x4: Tensor[(3, 3, 3, 3), float32] /* ty=Tensor[(3, 3, 3, 3), float32] span=from_string:39:57 */, %x5: Tensor[(1, 3, 224, 89), int8] /* ty=Tensor[(1, 3, 224, 89), int8] span=from_string:16:24 */, %x6: Tensor[(1, 3, 224, 32), int8] /* ty=Tensor[(1, 3, 224, 32), int8] span=from_string:19:24 */, %x7: Tensor[(1, 3, 224, 4), int8] /* ty=Tensor[(1, 3, 224, 4), int8] span=from_string:20:24 */, %x8: Tensor[(224), float32] /* ty=Tensor[(224), float32] span=from_string:30:45 */, %x9: Tensor[(224), float32] /* ty=Tensor[(224), float32] span=from_string:30:40 */, %x10: Tensor[(224), float32] /* ty=Tensor[(224), float32] span=from_string:30:34 */, %x11: Tensor[(224), float32] /* ty=Tensor[(224), float32] span=from_string:30:28 */) -> (Tensor[(1, 3, 224, 224), float16], Tensor[(1, 3, 224, 224), float32], Tensor[(1, 3, 224, 349), int8], Tensor[(1, 3, 224, 224), float32], Tensor[(3, 3, 3, 3), float32], Tensor[(1, 224, 3, 224), float32], Tensor[(1, 1, 3, 224, 224), int8]) {
  let %x_0 = 2f /* ty=float32 span=from_string:5:120 */;
  let %x_1 = 0.1f /* ty=float32 span=from_string:3:32 */;
  let %x_2 = 0 /* ty=int32 span=from_string:3:74 */;
  let %x_3 = qnn.dequantize(%x0, %x_1, %x_2);
  let %x_4 = nn.softmax(%x_3);
  let %x14: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] span=from_string:6:12 */ = add(%x_0, %x_4);
  let %x_5 = cast(%x_4, dtype="float16");
  let %x_6 = 1f /* ty=float32 span=from_string:6:20 */;
  let %x_7 = add(%x14, %x_6);
  let %x_8 = nn.conv2d(%x_7, %x2, padding=[1, 1, 1, 1], channels=3, kernel_size=[3, 3]);
  let %x_9 = 1f /* ty=float32 span=from_string:8:14 */;
  let %x_10 = add(%x_9, %x_8);
  let %x_11 = add(%x_8, %x_10);
  let %x_12 = nn.conv2d(%x_11, %x3, padding=[0, 0, 0, 0], channels=3, kernel_size=[1, 1]);
  let %x_13 = nn.conv2d(%x_11, %x4, padding=[1, 1, 1, 1], channels=3, kernel_size=[3, 3]);
  let %x_14 = add(%x_12, %x_13);
  let %x_15 = 0.2f /* ty=float32 span=from_string:12:32 */;
  let %x_16 = 0 /* ty=int32 span=from_string:12:75 */;
  let %x_17 = qnn.dequantize(%x1, %x_15, %x_16);
  let %x_18 = multiply(%x_3, %x_17);
  let %x_19 = 20f /* ty=float32 span=from_string:14:29 */;
  let %x_20 = 0 /* ty=int32 span=from_string:14:72 */;
  let %x_21 = qnn.quantize(%x_18, %x_19, %x_20, out_dtype="int8");
  let %x_22 = 0.5f /* ty=float32 span=from_string:15:33 */;
  let %x_23 = 0 /* ty=int32 span=from_string:15:76 */;
  let %x_24 = qnn.dequantize(%x_21, %x_22, %x_23);
  let %x_25 = 1.5f /* ty=float32 span=from_string:16:33 */;
  let %x_26 = 0 /* ty=int32 span=from_string:16:76 */;
  let %x_27 = qnn.dequantize(%x5, %x_25, %x_26);
  let %x_28 = (%x_24, %x_27) /* ty=(Tensor[(1, 3, 224, 224), float32], Tensor[(1, 3, 224, 89), float32]) span=from_string:18:21 */;
  let %x_29 = concatenate(%x_28, axis=-1);
  let %x_30 = annotation.stop_fusion(%x_29);
  let %x_31 = 2.5f /* ty=float32 span=from_string:19:33 */;
  let %x_32 = 0 /* ty=int32 span=from_string:19:76 */;
  let %x_33 = qnn.dequantize(%x6, %x_31, %x_32);
  let %x_34 = 3.5f /* ty=float32 span=from_string:20:33 */;
  let %x_35 = 0 /* ty=int32 span=from_string:20:76 */;
  let %x_36 = qnn.dequantize(%x7, %x_34, %x_35);
  let %x_37 = (%x_33, %x_36) /* ty=(Tensor[(1, 3, 224, 32), float32], Tensor[(1, 3, 224, 4), float32]) span=from_string:22:21 */;
  let %x_38 = concatenate(%x_37, axis=-1);
  let %x_39 = annotation.stop_fusion(%x_38);
  let %x_40 = (%x_30, %x_39) /* ty=(Tensor[(1, 3, 224, 313), float32], Tensor[(1, 3, 224, 36), float32]) span=from_string:26:21 */;
  let %x_41 = concatenate(%x_40, axis=-1);
  let %x_42 = 3.5f /* ty=float32 span=from_string:37:31 */;
  let %x_43 = 0 /* ty=int32 span=from_string:37:74 */;
  let %x_44 = qnn.quantize(%x_41, %x_42, %x_43, out_dtype="int8");
  let %x_45 = layout_transform(%x_18, src_layout="NHWC", dst_layout="NCHW4c");
  let %x_46 = nn.relu(%x_45);
  let %x_47 = layout_transform(%x_46, src_layout="NCHW4c", dst_layout="NCHW");
  let %x_48 = layout_transform(%x_47, src_layout="NCHW", dst_layout="NHWC");
  let %x_49 = 2f /* ty=float32 span=from_string:39:15 */;
  let %x_50 = add(%x_49, %x4);
  let %x_51 = nn.batch_norm(%x_47, %x11, %x10, %x9, %x8);
  let %x_52 = %x_51.0;
  let %x_53 = %x_51.0;
  let %x_54 = add(%x_52, %x_53);
  let %x_55 = 2f /* ty=float32 span=from_string:33:31 */;
  let %x_56 = 0 /* ty=int32 span=from_string:33:74 */;
  let %x_57 = qnn.dequantize(%x_21, %x_55, %x_56);
  let %x_58 = expand_dims(%x_57, axis=1);
  let %x_59 = 2f /* ty=float32 span=from_string:41:29 */;
  let %x_60 = 0 /* ty=int32 span=from_string:41:72 */;
  let %x_61 = qnn.quantize(%x_58, %x_59, %x_60, out_dtype="int8");
  let %x_62 = (%x_5, %x_14, %x_44, %x_48, %x_50, %x_54, %x_61) /* ty=(Tensor[(1, 3, 224, 224), float16], Tensor[(1, 3, 224, 224), float32], Tensor[(1, 3, 224, 349), int8], Tensor[(1, 3, 224, 224), float32], Tensor[(3, 3, 3, 3), float32], Tensor[(1, 224, 3, 224), float32], Tensor[(1, 1, 3, 224, 224), int8]) span=from_string:42:3 */;
  let %x_63 = %x_62;
  %x_63
}
