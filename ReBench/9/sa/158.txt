#[version = "0.0.5"]
def @main(%x0: Tensor[(1, 3, 224, 224), int8] /* ty=Tensor[(1, 3, 224, 224), int8] span=from_string:14:18 */, %x1: Tensor[(1, 3, 224, 224), int8] /* ty=Tensor[(1, 3, 224, 224), int8] span=from_string:18:24 */, %x2: Tensor[(3, 3, 3, 3), float32] /* ty=Tensor[(3, 3, 3, 3), float32] span=from_string:9:22 */, %x3: Tensor[(3, 3, 1, 1), float32] /* ty=Tensor[(3, 3, 1, 1), float32] span=from_string:12:22 */, %x4: Tensor[(3, 3, 3, 3), float32] /* ty=Tensor[(3, 3, 3, 3), float32] span=from_string:30:57 */, %x5: Tensor[(1, 3, 224, 89), int8] /* ty=Tensor[(1, 3, 224, 89), int8] span=from_string:15:15 */, %x6: Tensor[(1, 3, 224, 32), int8] /* ty=Tensor[(1, 3, 224, 32), int8] span=from_string:15:20 */, %x7: Tensor[(1, 3, 224, 4), int8] /* ty=Tensor[(1, 3, 224, 4), int8] span=from_string:15:25 */, %x8: Tensor[(224), float32] /* ty=Tensor[(224), float32] span=from_string:24:45 */, %x9: Tensor[(224), float32] /* ty=Tensor[(224), float32] span=from_string:24:40 */, %x10: Tensor[(224), float32] /* ty=Tensor[(224), float32] span=from_string:24:34 */, %x11: Tensor[(224), float32] /* ty=Tensor[(224), float32] span=from_string:24:28 */) -> (Tensor[(1, 3, 224, 224), float16], Tensor[(1, 3, 224, 224), float32], Tensor[(1, 3, 224, 349), int8], Tensor[(1, 3, 224, 224), float32], Tensor[(3, 3, 3, 3), float32], Tensor[(1, 224, 3, 224), float32], Tensor[(1, 1, 3, 224, 224), int8]) {
  let %x_0 = 0.1f /* ty=float32 span=from_string:3:32 */;
  let %x_1 = 0 /* ty=int32 span=from_string:3:74 */;
  let %x_2 = qnn.dequantize(%x0, %x_0, %x_1);
  let %x_3 = nn.softmax(%x_2);
  let %x_4 = cast(%x_3, dtype="float16");
  let %x_5 = 2f /* ty=float32 span=from_string:7:14 */;
  let %x_6 = zeros(shape=[1], dtype="float32");
  let %x_7 = add(%x_3, %x_6);
  let %x_8 = add(%x_5, %x_7);
  let %x_9 = 1f /* ty=float32 span=from_string:8:18 */;
  let %x_10 = add(%x_8, %x_9);
  let %x_11 = nn.conv2d(%x_10, %x2, padding=[1, 1, 1, 1], channels=3, kernel_size=[3, 3]);
  let %x_12 = 1f /* ty=float32 span=from_string:10:14 */;
  let %x_13 = add(%x_12, %x_11);
  let %x_14 = add(%x_11, %x_13);
  let %x_15 = nn.conv2d(%x_14, %x3, padding=[0, 0, 0, 0], channels=3, kernel_size=[1, 1]);
  let %x_16 = nn.conv2d(%x_14, %x4, padding=[1, 1, 1, 1], channels=3, kernel_size=[3, 3]);
  let %x_17 = add(%x_15, %x_16);
  let %x_18 = 0.1f /* ty=float32 span=from_string:14:32 */;
  let %x_19 = 0 /* ty=int32 span=from_string:14:75 */;
  let %x_20 = 0.2f /* ty=float32 span=from_string:14:119 */;
  let %x_21 = 0 /* ty=int32 span=from_string:14:163 */;
  let %x_22 = 20f /* ty=float32 span=from_string:14:207 */;
  let %x_23 = 0 /* ty=int32 span=from_string:14:251 */;
  let %x_24 = qnn.mul(%x0, %x1, %x_18, %x_19, %x_20, %x_21, %x_22, %x_23);
  let %x_25 = (%x_24, %x5, %x6, %x7) /* ty=(Tensor[(1, 3, 224, 224), int8], Tensor[(1, 3, 224, 89), int8], Tensor[(1, 3, 224, 32), int8], Tensor[(1, 3, 224, 4), int8]) span=from_string:28:25 */;
  let %x_26 = 0.5f /* ty=float32 span=from_string:16:14 */;
  let %x_27 = 1.5f /* ty=float32 span=from_string:16:60 */;
  let %x_28 = 2.5f /* ty=float32 span=from_string:16:106 */;
  let %x_29 = 3.5f /* ty=float32 span=from_string:16:153 */;
  let %x_30 = (%x_26, %x_27, %x_28, %x_29) /* ty=(float32, float32, float32, float32) span=from_string:28:30 */;
  let %x_31 = 0 /* ty=int32 span=from_string:17:11 */;
  let %x_32 = 0 /* ty=int32 span=from_string:17:52 */;
  let %x_33 = 0 /* ty=int32 span=from_string:17:93 */;
  let %x_34 = 0 /* ty=int32 span=from_string:17:134 */;
  let %x_35 = (%x_31, %x_32, %x_33, %x_34) /* ty=(int32, int32, int32, int32) span=from_string:28:35 */;
  let %x_36 = 3.5f /* ty=float32 span=from_string:28:44 */;
  let %x_37 = 0 /* ty=int32 span=from_string:28:87 */;
  let %x_38 = qnn.concatenate(%x_25, %x_30, %x_35, %x_36, %x_37, axis=-1);
  let %x_39 = 0.2f /* ty=float32 span=from_string:18:33 */;
  let %x_40 = 0 /* ty=int32 span=from_string:18:76 */;
  let %x_41 = qnn.dequantize(%x1, %x_39, %x_40);
  let %x_42 = multiply(%x_2, %x_41);
  let %x_43 = layout_transform(%x_42, src_layout="NHWC", dst_layout="NCHW");
  let %x_44 = layout_transform(%x_43, src_layout="NCHW", dst_layout="NCHW4c");
  let %x_45 = nn.relu(%x_44);
  let %x_46 = layout_transform(%x_45, src_layout="NCHW4c", dst_layout="NCHW");
  let %x_47 = layout_transform(%x_46, src_layout="NCHW", dst_layout="NHWC");
  let %x_48 = 2f /* ty=float32 span=from_string:30:15 */;
  let %x_49 = add(%x_48, %x4);
  let %x_50 = nn.batch_norm(%x_46, %x11, %x10, %x9, %x8);
  let %x_51 = %x_50.0;
  let %x_52 = add(%x_51, %x_51);
  let %x_53 = expand_dims(%x_24, axis=1);
  let %x_54 = (%x_4, %x_17, %x_38, %x_47, %x_49, %x_52, %x_53) /* ty=(Tensor[(1, 3, 224, 224), float16], Tensor[(1, 3, 224, 224), float32], Tensor[(1, 3, 224, 349), int8], Tensor[(1, 3, 224, 224), float32], Tensor[(3, 3, 3, 3), float32], Tensor[(1, 224, 3, 224), float32], Tensor[(1, 1, 3, 224, 224), int8]) span=from_string:3:3 */;
  %x_54
}
