#[version = "0.0.5"]
def @main(%x0: Tensor[(1, 224, 224, 3), int8] /* ty=Tensor[(1, 224, 224, 3), int8] span=from_string:35:131 */, %x1: Tensor[(16, 3, 5, 5), int8] /* ty=Tensor[(16, 3, 5, 5), int8] span=from_string:23:125 */, %x2: Tensor[(16), int32] /* ty=Tensor[(16), int32] span=from_string:3:88 */, %x3: Tensor[(84), int32] /* ty=Tensor[(84), int32] span=from_string:4:88 */) -> (Tensor[(1, 16, 220, 220), int8], Tensor[(16, 3, 3, 3), int8], Tensor[(16), int32], Tensor[(1, 16, 220, 220), float32], Tensor[(84), int32], Tensor[(1, 3, 1, 1), float32], Tensor[(16), float16], Tensor[(1, 224, 224, 3), int8], Tensor[(16, 3, 5, 5), float32], float32) {
  %0 = qnn.dequantize(%x0, 2f /* ty=float32 span=from_string:5:64 */, 0 /* ty=int32 span=from_string:6:61 */) /* ty=Tensor[(1, 224, 224, 3), float32] span=from_string:7:114 */;
  %1 = transpose(%0, axes=[0, 3, 1, 2]) /* ty=Tensor[(1, 3, 224, 224), float32] span=from_string:8:115 */;
  %2 = qnn.dequantize(%x1, 0.5f /* ty=float32 span=from_string:9:67 */, 0 /* ty=int32 span=from_string:10:62 */) /* ty=Tensor[(16, 3, 5, 5), float32] span=from_string:11:109 */;
  %3 = qnn.dequantize(%x2, 2f /* ty=float32 span=from_string:13:65 */, 0 /* ty=int32 span=from_string:14:62 */) /* ty=Tensor[(16), float32] span=from_string:15:92 */;
  %4 = nn.conv2d(%1, %2, padding=[0, 0, 0, 0], kernel_size=[5, 5]) /* ty=Tensor[(1, 16, 220, 220), float32] span=from_string:12:117 */;
  %5 = expand_dims(%3, axis=1, num_newaxis=2) /* ty=Tensor[(16, 1, 1), float32] span=from_string:17:128 */;
  %6 = add(%4, %5) /* ty=Tensor[(1, 16, 220, 220), float32] span=from_string:17:118 */;
  %7 = qnn.dequantize(%x1, 2f /* ty=float32 span=from_string:21:66 */, -12 /* ty=int32 span=from_string:22:65 */) /* ty=Tensor[(16, 3, 5, 5), float32] span=from_string:23:110 */;
  %8 = nn.avg_pool2d(%7, pool_size=[3, 3], padding=[0, 0, 0, 0]) /* ty=Tensor[(16, 3, 3, 3), float32] span=from_string:24:110 */;
  %9 = nn.softmax(%3) /* ty=Tensor[(16), float32] span=from_string:31:92 */;
  %10 = qnn.dequantize(%x0, 0.1f /* ty=float32 span=from_string:33:68 */, 10 /* ty=int32 span=from_string:34:64 */) /* ty=Tensor[(1, 224, 224, 3), float32] span=from_string:35:116 */;
  %11 = multiply(%10, 1f /* ty=float32 span=from_string:36:66 */) /* ty=Tensor[(1, 224, 224, 3), float32] span=from_string:37:117 */;
  %12 = sqrt(%7) /* ty=Tensor[(16, 3, 5, 5), float32] span=from_string:42:110 */;
  %13 = qnn.quantize(%6, 1f /* ty=float32 span=from_string:18:66 */, 0 /* ty=int32 span=from_string:19:63 */, out_dtype="int8") /* ty=Tensor[(1, 16, 220, 220), int8] span=from_string:20:114 */;
  %14 = qnn.quantize(%8, 0.5f /* ty=float32 span=from_string:25:68 */, 10 /* ty=int32 span=from_string:26:64 */, out_dtype="int8") /* ty=Tensor[(16, 3, 3, 3), int8] span=from_string:27:106 */;
  %15 = ones(shape=[1, 16, 220, 220], dtype="float32") /* ty=Tensor[(1, 16, 220, 220), float32] span=from_string:28:118 */;
  %16 = zeros_like(%x3) /* ty=Tensor[(84), int32] span=from_string:29:90 */;
  %17 = nn.global_max_pool2d(%1) /* ty=Tensor[(1, 3, 1, 1), float32] span=from_string:30:108 */;
  %18 = cast(%9, dtype="float16") /* ty=Tensor[(16), float16] span=from_string:32:92 */;
  %19 = qnn.quantize(%11, 0.1f /* ty=float32 span=from_string:38:68 */, 10 /* ty=int32 span=from_string:39:64 */, out_dtype="int8") /* ty=Tensor[(1, 224, 224, 3), int8] span=from_string:40:112 */;
  %20 = divide(2f /* ty=float32 span=from_string:41:66 */, %12) /* ty=Tensor[(16, 3, 5, 5), float32] span=from_string:43:110 */;
  (%13, %14, %x2, %15, %16, %17, %18, %19, %20, 4f /* ty=float32 span=from_string:44:66 */) /* ty=(Tensor[(1, 16, 220, 220), int8], Tensor[(16, 3, 3, 3), int8], Tensor[(16), int32], Tensor[(1, 16, 220, 220), float32], Tensor[(84), int32], Tensor[(1, 3, 1, 1), float32], Tensor[(16), float16], Tensor[(1, 224, 224, 3), int8], Tensor[(16, 3, 5, 5), float32], float32) span=from_string:45:594 */
}
