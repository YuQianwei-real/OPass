#[version = "0.0.5"]
def @main(%x0: Tensor[(1, 224, 224, 3), int8] /* ty=Tensor[(1, 224, 224, 3), int8] span=from_string:14:23 */, %x1: Tensor[(16, 3, 5, 5), int8] /* ty=Tensor[(16, 3, 5, 5), int8] span=from_string:11:23 */, %x2: Tensor[(16), int32] /* ty=Tensor[(16), int32] span=from_string:9:23 */, %x3: Tensor[(84), int32] /* ty=Tensor[(84), int32] span=from_string:4:88 */) -> (Tensor[(1, 16, 220, 220), int8], Tensor[(16, 3, 3, 3), int8], Tensor[(16), int32], Tensor[(1, 16, 220, 220), float32], Tensor[(84), int32], Tensor[(1, 3, 1, 1), float32], Tensor[(16), float16], Tensor[(1, 224, 224, 3), int8], Tensor[(16, 3, 5, 5), float32], float32) {
  let %x4: Tensor[(16), int32] /* ty=Tensor[(16), int32] span=from_string:25:14 */ = %x2;
  let %x5: Tensor[(84), int32] /* ty=Tensor[(84), int32] span=from_string:20:20 */ = %x3;
  %0 = qnn.dequantize(%x0, 2f /* ty=float32 span=from_string:5:30 */, 0 /* ty=int32 span=from_string:5:72 */) /* ty=Tensor[(1, 224, 224, 3), float32] span=from_string:6:18 */;
  %1 = transpose(%0, axes=[0, 3, 1, 2]) /* ty=Tensor[(1, 3, 224, 224), float32] span=from_string:21:30 */;
  %2 = qnn.dequantize(%x1, 0.5f /* ty=float32 span=from_string:7:32 */, 0 /* ty=int32 span=from_string:7:74 */) /* ty=Tensor[(16, 3, 5, 5), float32] span=from_string:8:22 */;
  %3 = qnn.dequantize(%x2, 2f /* ty=float32 span=from_string:9:30 */, 0 /* ty=int32 span=from_string:9:72 */) /* ty=Tensor[(16), float32] span=from_string:13:19 */;
  %4 = nn.conv2d(%1, %2, padding=[0, 0, 0, 0], kernel_size=[5, 5]) /* ty=Tensor[(1, 16, 220, 220), float32] span=from_string:10:20 */;
  %5 = expand_dims(%3, axis=1, num_newaxis=2) /* ty=Tensor[(16, 1, 1), float32] */;
  %6 = add(%4, %5) /* ty=Tensor[(1, 16, 220, 220), float32] */;
  %7 = qnn.dequantize(%x1, 2f /* ty=float32 span=from_string:11:30 */, -12 /* ty=int32 span=from_string:11:75 */) /* ty=Tensor[(16, 3, 5, 5), float32] span=from_string:16:14 */;
  %8 = nn.avg_pool2d(%7, pool_size=[3, 3], padding=[0, 0, 0, 0]) /* ty=Tensor[(16, 3, 3, 3), float32] span=from_string:18:22 */;
  %9 = nn.softmax(%3) /* ty=Tensor[(16), float32] span=from_string:22:14 */;
  %10 = qnn.dequantize(%x0, 0.1f /* ty=float32 span=from_string:14:32 */, 10 /* ty=int32 span=from_string:14:76 */) /* ty=Tensor[(1, 224, 224, 3), float32] span=from_string:15:19 */;
  %11 = multiply(%10, 1f /* ty=float32 span=from_string:15:25 */) /* ty=Tensor[(1, 224, 224, 3), float32] span=from_string:23:22 */;
  %12 = sqrt(%7) /* ty=Tensor[(16, 3, 5, 5), float32] span=from_string:24:60 */;
  %13 = qnn.quantize(%6, 1f /* ty=float32 span=from_string:17:28 */, 0 /* ty=int32 span=from_string:17:70 */, out_dtype="int8") /* ty=Tensor[(1, 16, 220, 220), int8] span=from_string:25:4 */;
  %14 = qnn.quantize(%8, 0.5f /* ty=float32 span=from_string:18:30 */, 10 /* ty=int32 span=from_string:18:74 */, out_dtype="int8") /* ty=Tensor[(16, 3, 3, 3), int8] span=from_string:25:9 */;
  %15 = ones(shape=[1, 16, 220, 220], dtype="float32") /* ty=Tensor[(1, 16, 220, 220), float32] span=from_string:25:19 */;
  %16 = zeros_like(%x5) /* ty=Tensor[(84), int32] span=from_string:25:24 */;
  %17 = nn.global_max_pool2d(%1) /* ty=Tensor[(1, 3, 1, 1), float32] span=from_string:25:29 */;
  %18 = cast(%9, dtype="float16") /* ty=Tensor[(16), float16] span=from_string:25:34 */;
  %19 = qnn.quantize(%11, 0.1f /* ty=float32 span=from_string:23:31 */, 10 /* ty=int32 span=from_string:23:75 */, out_dtype="int8") /* ty=Tensor[(1, 224, 224, 3), int8] span=from_string:25:39 */;
  %20 = divide(2f /* ty=float32 span=from_string:24:18 */, %12) /* ty=Tensor[(16, 3, 5, 5), float32] span=from_string:25:44 */;
  (%13, %14, %x4, %15, %16, %17, %18, %19, %20, 4f /* ty=float32 span=from_string:25:51 */) /* ty=(Tensor[(1, 16, 220, 220), int8], Tensor[(16, 3, 3, 3), int8], Tensor[(16), int32], Tensor[(1, 16, 220, 220), float32], Tensor[(84), int32], Tensor[(1, 3, 1, 1), float32], Tensor[(16), float16], Tensor[(1, 224, 224, 3), int8], Tensor[(16, 3, 5, 5), float32], float32) span=from_string:25:3 */
}
