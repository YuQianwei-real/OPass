digraph static_mod {
	node [fontname="Linux Biolinum O" shape=record]
	in0 [label="in0: Tensor[(1, 224, 224, 3), int8]"]
	con0 [label="con0: float32"]
	con1 [label="con1: int32"]
	opr0 [label="{{<i0>Tensor[(1, 224, 224, 3), int8]|<i1>float32|<i2>int32}|qnn.dequantize\naxis=-1|{<o0>Tensor[(1, 224, 224, 3), float32]}}"]
	in0 -> opr0:i0
	con0 -> opr0:i1
	con1 -> opr0:i2
	opr1 [label="{{<i0>Tensor[(1, 224, 224, 3), float32]}|transpose\naxes=[0, 3, 1, 2]|{<o0>Tensor[(1, 3, 224, 224), float32]}}"]
	opr0:o0 -> opr1:i0
	in1 [label="in1: Tensor[(16, 3, 5, 5), int8]"]
	con2 [label="con2: float32"]
	con3 [label="con3: int32"]
	opr2 [label="{{<i0>Tensor[(16, 3, 5, 5), int8]|<i1>float32|<i2>int32}|qnn.dequantize\naxis=-1|{<o0>Tensor[(16, 3, 5, 5), float32]}}"]
	in1 -> opr2:i0
	con2 -> opr2:i1
	con3 -> opr2:i2
	opr3 [label="{{<i0>Tensor[(1, 3, 224, 224), float32]|<i1>Tensor[(16, 3, 5, 5), float32]}|nn.conv2d\nstrides=[1, 1]\npadding=[0, 0, 0, 0]\ndilation=[1, 1]\ngroups=1\nchannels=None\nkernel_size=[5, 5]\ndata_layout=\"NCHW\"\nkernel_layout=\"OIHW\"\nout_layout=\"\"\nout_dtype=\"\"|{<o0>Tensor[(1, 16, 220, 220), float32]}}"]
	opr1:o0 -> opr3:i0
	opr2:o0 -> opr3:i1
	in2 [label="in2: Tensor[(16,), int32]"]
	con4 [label="con4: float32"]
	con5 [label="con5: int32"]
	opr4 [label="{{<i0>Tensor[(16,), int32]|<i1>float32|<i2>int32}|qnn.dequantize\naxis=-1|{<o0>Tensor[(16,), float32]}}"]
	in2 -> opr4:i0
	con4 -> opr4:i1
	con5 -> opr4:i2
	opr5 [label="{{<i0>Tensor[(1, 16, 220, 220), float32]|<i1>Tensor[(16,), float32]}|nn.bias_add\naxis=1|{<o0>Tensor[(1, 16, 220, 220), float32]}}"]
	opr3:o0 -> opr5:i0
	opr4:o0 -> opr5:i1
	con6 [label="con6: float32"]
	con7 [label="con7: int32"]
	opr6 [label="{{<i0>Tensor[(1, 16, 220, 220), float32]|<i1>float32|<i2>int32}|qnn.quantize\nout_dtype=\"int8\"\naxis=-1|{<o0>Tensor[(1, 16, 220, 220), int8]}}"]
	opr5:o0 -> opr6:i0
	con6 -> opr6:i1
	con7 -> opr6:i2
	con8 [label="con8: float32"]
	con9 [label="con9: int32"]
	opr7 [label="{{<i0>Tensor[(16, 3, 5, 5), int8]|<i1>float32|<i2>int32}|qnn.dequantize\naxis=-1|{<o0>Tensor[(16, 3, 5, 5), float32]}}"]
	in1 -> opr7:i0
	con8 -> opr7:i1
	con9 -> opr7:i2
	opr8 [label="{{<i0>Tensor[(16, 3, 5, 5), float32]}|nn.avg_pool2d\npool_size=[3, 3]\nstrides=[1, 1]\ndilation=[1, 1]\npadding=[0, 0, 0, 0]\nlayout=\"NCHW\"\nout_layout=\"\"\nceil_mode=0\ncount_include_pad=0|{<o0>Tensor[(16, 3, 3, 3), float32]}}"]
	opr7:o0 -> opr8:i0
	con10 [label="con10: float32"]
	con11 [label="con11: int32"]
	opr9 [label="{{<i0>Tensor[(16, 3, 3, 3), float32]|<i1>float32|<i2>int32}|qnn.quantize\nout_dtype=\"int8\"\naxis=-1|{<o0>Tensor[(16, 3, 3, 3), int8]}}"]
	opr8:o0 -> opr9:i0
	con10 -> opr9:i1
	con11 -> opr9:i2
	opr10 [label="{{<i0>Tensor[(16,), int32]}|let\n|{<o0>Tensor[(16,), int32]}}"]
	in2 -> opr10:i0
	opr11 [label="{{}|ones\nshape=[1, 16, 220, 220]\ndtype=\"float32\"|{<o0>Tensor[(1, 16, 220, 220), float32]}}"]
	in3 [label="in3: Tensor[(84,), int32]"]
	opr12 [label="{{<i0>Tensor[(84,), int32]}|let\n|{<o0>Tensor[(84,), int32]}}"]
	in3 -> opr12:i0
	opr13 [label="{{<i0>Tensor[(84,), int32]}|zeros_like\n|{<o0>Tensor[(84,), int32]}}"]
	opr12:o0 -> opr13:i0
	opr14 [label="{{<i0>Tensor[(1, 3, 224, 224), float32]}|nn.global_max_pool2d\nlayout=\"NCHW\"\nout_layout=\"\"|{<o0>Tensor[(1, 3, 1, 1), float32]}}"]
	opr1:o0 -> opr14:i0
	opr15 [label="{{<i0>Tensor[(16,), float32]}|nn.softmax\naxis=-1|{<o0>Tensor[(16,), float32]}}"]
	opr4:o0 -> opr15:i0
	opr16 [label="{{<i0>Tensor[(16,), float32]}|cast\ndtype=\"float16\"|{<o0>Tensor[(16,), float16]}}"]
	opr15:o0 -> opr16:i0
	con12 [label="con12: float32"]
	con13 [label="con13: int32"]
	opr17 [label="{{<i0>Tensor[(1, 224, 224, 3), int8]|<i1>float32|<i2>int32}|qnn.dequantize\naxis=-1|{<o0>Tensor[(1, 224, 224, 3), float32]}}"]
	in0 -> opr17:i0
	con12 -> opr17:i1
	con13 -> opr17:i2
	con14 [label="con14: float32"]
	opr18 [label="{{<i0>Tensor[(1, 224, 224, 3), float32]|<i1>float32}|multiply\n|{<o0>Tensor[(1, 224, 224, 3), float32]}}"]
	opr17:o0 -> opr18:i0
	con14 -> opr18:i1
	con15 [label="con15: float32"]
	con16 [label="con16: int32"]
	opr19 [label="{{<i0>Tensor[(1, 224, 224, 3), float32]|<i1>float32|<i2>int32}|qnn.quantize\nout_dtype=\"int8\"\naxis=-1|{<o0>Tensor[(1, 224, 224, 3), int8]}}"]
	opr18:o0 -> opr19:i0
	con15 -> opr19:i1
	con16 -> opr19:i2
	con17 [label="con17: float32"]
	opr20 [label="{{<i0>Tensor[(16, 3, 5, 5), float32]}|sqrt\n|{<o0>Tensor[(16, 3, 5, 5), float32]}}"]
	opr7:o0 -> opr20:i0
	opr21 [label="{{<i0>float32|<i1>Tensor[(16, 3, 5, 5), float32]}|divide\n|{<o0>Tensor[(16, 3, 5, 5), float32]}}"]
	con17 -> opr21:i0
	opr20:o0 -> opr21:i1
	con18 [label="con18: float32"]
	opr22 [label="{{<i0>Tensor[(1, 16, 220, 220), int8]|<i1>Tensor[(16, 3, 3, 3), int8]|<i2>Tensor[(16,), int32]|<i3>Tensor[(1, 16, 220, 220), float32]|<i4>Tensor[(84,), int32]|<i5>Tensor[(1, 3, 1, 1), float32]|<i6>Tensor[(16,), float16]|<i7>Tensor[(1, 224, 224, 3), int8]|<i8>Tensor[(16, 3, 5, 5), float32]|<i9>float32}|tuple\n|{<o0>(Tensor[(1, 16, 220, 220), int8], Tensor[(16, 3, 3, 3), int8], Tensor[(16,), int32], Tensor[(1, 16, 220, 220), float32], Tensor[(84,), int32], Tensor[(1, 3, 1, 1), float32], Tensor[(16,), float16], Tensor[(1, 224, 224, 3), int8], Tensor[(16, 3, 5, 5), float32], float32)}}"]
	opr6:o0 -> opr22:i0
	opr9:o0 -> opr22:i1
	opr10:o0 -> opr22:i2
	opr11:o0 -> opr22:i3
	opr13:o0 -> opr22:i4
	opr14:o0 -> opr22:i5
	opr16:o0 -> opr22:i6
	opr19:o0 -> opr22:i7
	opr21:o0 -> opr22:i8
	con18 -> opr22:i9
	out0 [label="out0: (Tensor[(1, 16, 220, 220), int8], Tensor[(16, 3, 3, 3), int8], Tensor[(16,), int32], Tensor[(1, 16, 220, 220), float32], Tensor[(84,), int32], Tensor[(1, 3, 1, 1), float32], Tensor[(16,), float16], Tensor[(1, 224, 224, 3), int8], Tensor[(16, 3, 5, 5), float32], float32)"]
	opr22:o0 -> out0
}
