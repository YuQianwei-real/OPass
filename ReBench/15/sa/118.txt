#[version = "0.0.5"]
def @main(%x0: Tensor[(1, 224, 224, 3), int8] /* ty=Tensor[(1, 224, 224, 3), int8] span=from_string:12:23 */, %x1: Tensor[(16, 3, 5, 5), int8] /* ty=Tensor[(16, 3, 5, 5), int8] span=from_string:9:23 */, %x2: Tensor[(16), int32] /* ty=Tensor[(16), int32] span=from_string:23:14 */, %x3: Tensor[(84), int32] /* ty=Tensor[(84), int32] span=from_string:18:20 */) -> (Tensor[(1, 16, 220, 220), int8], Tensor[(16, 3, 3, 3), int8], Tensor[(16), int32], Tensor[(1, 16, 220, 220), float32], Tensor[(84), int32], Tensor[(1, 3, 1, 1), float32], Tensor[(16), float16], Tensor[(1, 224, 224, 3), int8], Tensor[(16, 3, 5, 5), float32], float32) {
  %0 = qnn.dequantize(%x0, 2f /* ty=float32 span=from_string:3:30 */, 0 /* ty=int32 span=from_string:3:72 */) /* ty=Tensor[(1, 224, 224, 3), float32] span=from_string:4:18 */;
  %1 = transpose(%0, axes=[0, 3, 1, 2]) /* ty=Tensor[(1, 3, 224, 224), float32] span=from_string:19:30 */;
  %2 = qnn.dequantize(%x1, 0.5f /* ty=float32 span=from_string:5:32 */, 0 /* ty=int32 span=from_string:5:74 */) /* ty=Tensor[(16, 3, 5, 5), float32] span=from_string:6:22 */;
  %3 = nn.conv2d(%1, %2, padding=[0, 0, 0, 0], kernel_size=[5, 5]) /* ty=Tensor[(1, 16, 220, 220), float32] span=from_string:8:20 */;
  %4 = qnn.dequantize(%x2, 2f /* ty=float32 span=from_string:7:30 */, 0 /* ty=int32 span=from_string:7:72 */) /* ty=Tensor[(16), float32] span=from_string:11:19 */;
  %5 = nn.bias_add(%3, %4) /* ty=Tensor[(1, 16, 220, 220), float32] span=from_string:15:22 */;
  %6 = qnn.dequantize(%x1, 2f /* ty=float32 span=from_string:9:30 */, -12 /* ty=int32 span=from_string:9:74 */) /* ty=Tensor[(16, 3, 5, 5), float32] span=from_string:14:14 */;
  %7 = nn.avg_pool2d(%6, pool_size=[3, 3], padding=[0, 0, 0, 0]) /* ty=Tensor[(16, 3, 3, 3), float32] span=from_string:16:22 */;
  %8 = nn.softmax(%4) /* ty=Tensor[(16), float32] span=from_string:20:14 */;
  %9 = qnn.dequantize(%x0, 0.1f /* ty=float32 span=from_string:12:32 */, 10 /* ty=int32 span=from_string:12:76 */) /* ty=Tensor[(1, 224, 224, 3), float32] span=from_string:13:19 */;
  %10 = multiply(%9, 1f /* ty=float32 span=from_string:13:25 */) /* ty=Tensor[(1, 224, 224, 3), float32] span=from_string:21:22 */;
  %11 = sqrt(%6) /* ty=Tensor[(16, 3, 5, 5), float32] span=from_string:22:60 */;
  %12 = qnn.quantize(%5, 1f /* ty=float32 span=from_string:15:28 */, 0 /* ty=int32 span=from_string:15:71 */, out_dtype="int8") /* ty=Tensor[(1, 16, 220, 220), int8] span=from_string:23:4 */;
  %13 = qnn.quantize(%7, 0.5f /* ty=float32 span=from_string:16:30 */, 10 /* ty=int32 span=from_string:16:74 */, out_dtype="int8") /* ty=Tensor[(16, 3, 3, 3), int8] span=from_string:23:9 */;
  %14 = ones(shape=[1, 16, 220, 220], dtype="float32") /* ty=Tensor[(1, 16, 220, 220), float32] span=from_string:23:19 */;
  %15 = zeros_like(%x3) /* ty=Tensor[(84), int32] span=from_string:23:24 */;
  %16 = nn.global_max_pool2d(%1) /* ty=Tensor[(1, 3, 1, 1), float32] span=from_string:23:29 */;
  %17 = cast(%8, dtype="float16") /* ty=Tensor[(16), float16] span=from_string:23:34 */;
  %18 = qnn.quantize(%10, 0.1f /* ty=float32 span=from_string:21:31 */, 10 /* ty=int32 span=from_string:21:75 */, out_dtype="int8") /* ty=Tensor[(1, 224, 224, 3), int8] span=from_string:23:39 */;
  %19 = divide(2f /* ty=float32 span=from_string:22:18 */, %11) /* ty=Tensor[(16, 3, 5, 5), float32] span=from_string:23:44 */;
  (%12, %13, %x2, %14, %15, %16, %17, %18, %19, 4f /* ty=float32 span=from_string:23:51 */) /* ty=(Tensor[(1, 16, 220, 220), int8], Tensor[(16, 3, 3, 3), int8], Tensor[(16), int32], Tensor[(1, 16, 220, 220), float32], Tensor[(84), int32], Tensor[(1, 3, 1, 1), float32], Tensor[(16), float16], Tensor[(1, 224, 224, 3), int8], Tensor[(16, 3, 5, 5), float32], float32) span=from_string:3:3 */
}
